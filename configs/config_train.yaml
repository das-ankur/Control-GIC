ckpt_path: 
wandb_project_name: 'cGIC'

trainer:
  log_every_n_steps: 30
  precision: 32
  gradient_clip_val: 1.0
  gradient_clip_algorithm: 'value'
  gpus: 4
  num_nodes: 1
  accelerator: 'gpu'
  strategy: 'ddp'
  max_steps: 200000
  replace_sampler_ddp: True
  val_check_interval: 1500

ModelCheckpoint:
  dirpath: './all_saves/'
  filename: "{step}-model"
  save_top_k: -1
  every_n_train_steps: 1500

model:
  target: control.models.model.MOVQ
  params:
    ignore_keys: [quantize.embedding_counter]
    learning_rate: 1e-5
    ema_decay: 0.9999
    embed_dim: 4
    n_embed: 16384
    monitor: val/rec_loss
    image_size: 256
    entropy_patch_size: 8
    ckpt_path: ''
    encoderconfig:
      double_z: false
      z_channels: 4
      resolution: 256
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 2
      - 2
      - 4
      - 4
      num_res_blocks: 2
      attn_resolutions:
      - 32
      dropout: 0.0
      update_router: false
      router_config:
        target: control.modules.vqvae.RouterTriple.TripleGrainFixedEntropyRouter
        params:
          coarse_grain_ratito: 0.1
          medium_grain_ratito: 0.4
    ddconfig:
      double_z: false
      z_channels: 4
      resolution: 256
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 2
      - 2
      - 4
      - 4
      num_res_blocks: 2
      attn_resolutions:
      - 32
      dropout: 0.0
    lossconfig:
      target: control.modules.losses.vqperceptual.VQLPIPSWithDiscriminator2
      params:
        disc_conditional: false
        disc_in_channels: 3
        disc_num_layers: 2
        disc_start: 1
        disc_weight: 0.8
        codebook_weight: 1.0
        perceptual_weight: 1.0

        
data:
  train:
    datadir: 
    image_size: 256
    batch_size: 2
    shuffle: True
    num_workers: 8
    is_train: True
  validation:
    datadir: 
    image_size: 256
    batch_size: 4
    shuffle: False
    num_workers: 8
    is_train: False
